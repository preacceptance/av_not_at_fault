# summary statistics
aggregate(vB_m_v_d_sue ~ agent_name, data = d_merged, FUN = mean)
aggregate(vB_m_v_d_sue ~ intv_appld, data = d_merged, FUN = mean)
## Vehicle B Counterfactual (M)
vB_countf_mod <- aov(vB_cntrfctl ~ as.factor(agent_n) * as.factor(intv_n), data = d_merged)
summary(vB_countf_mod)
anova_stats(vB_countf_mod)
# summary statistics
aggregate(vB_cntrfctl ~ agent_name, data = d_merged, FUN = mean)
aggregate(vB_cntrfctl ~ intv_appld, data = d_merged, FUN = mean)
## Sue, at-fault (DV)
t.test(vA_sue ~ agent_name, data = d_merged[d_merged$intv_appld=="yes", ])
t.test(vA_sue ~ agent_name, data = d_merged[d_merged$intv_appld=="no", ])
cohen.d(d_merged[d_merged$intv_appld=="yes", ]$vA_sue, d_merged[d_merged$intv_appld=="yes", ]$agent_name)
cohen.d(d_merged[d_merged$intv_appld=="no", ]$vA_sue, d_merged[d_merged$intv_appld=="no", ]$agent_name)
## Sue, Manufacturer vs Manufacturer (DV)
t.test(vB_m_v_m_sue ~ agent_name, data = d_merged[d_merged$intv_appld=="yes", ])
t.test(vB_m_v_m_sue ~ agent_name, data = d_merged[d_merged$intv_appld=="no", ])
cohen.d(d_merged[d_merged$intv_appld=="yes", ]$vB_m_v_m_sue, d_merged[d_merged$intv_appld=="yes", ]$agent_name)
cohen.d(d_merged[d_merged$intv_appld=="no", ]$vB_m_v_m_sue, d_merged[d_merged$intv_appld=="no", ]$agent_name)
## Sue, Manufacturer vs Driver (DV)
t.test(vB_m_v_d_sue ~ agent_name, data = d_merged[d_merged$intv_appld=="yes", ])
t.test(vB_m_v_d_sue ~ agent_name, data = d_merged[d_merged$intv_appld=="no", ])
cohen.d(d_merged[d_merged$intv_appld=="yes", ]$vB_m_v_d_sue, d_merged[d_merged$intv_appld=="yes", ]$agent_name)
cohen.d(d_merged[d_merged$intv_appld=="no", ]$vB_m_v_d_sue, d_merged[d_merged$intv_appld=="no", ]$agent_name)
## Vehicle A Counterfactual (M)
t.test(vA_cntrfctl ~ agent_name, data = d_merged[d_merged$intv_appld=="yes", ])
t.test(vA_cntrfctl ~ agent_name, data = d_merged[d_merged$intv_appld=="no", ])
cohen.d(d_merged[d_merged$intv_appld=="yes", ]$vA_cntrfctl, d_merged[d_merged$intv_appld=="yes", ]$agent_name)
cohen.d(d_merged[d_merged$intv_appld=="no", ]$vA_cntrfctl, d_merged[d_merged$intv_appld=="no", ]$agent_name)
## Vehicle B Counterfactual (M)
t.test(vB_cntrfctl ~ agent_name, data = d_merged[d_merged$intv_appld=="yes", ])
t.test(vB_cntrfctl ~ agent_name, data = d_merged[d_merged$intv_appld=="no", ])
cohen.d(d_merged[d_merged$intv_appld=="yes", ]$vB_cntrfctl, d_merged[d_merged$intv_appld=="yes", ]$agent_name)
cohen.d(d_merged[d_merged$intv_appld=="no", ]$vB_cntrfctl, d_merged[d_merged$intv_appld=="no", ]$agent_name)
# Could have done more to avoid (M)
t.test(avoid ~ agent_name, data = d_merged[d_merged$intv_appld=="yes", ])
t.test(avoid ~ agent_name, data = d_merged[d_merged$intv_appld=="no", ])
cohen.d(d_merged[d_merged$intv_appld=="yes", ]$avoid, d_merged[d_merged$intv_appld=="yes", ]$agent_name)
cohen.d(d_merged[d_merged$intv_appld=="no", ]$avoid, d_merged[d_merged$intv_appld=="no", ]$agent_name)
# Averaged mediator (M)
t.test(med ~ agent_name, data = d_merged[d_merged$intv_appld=="yes", ])
t.test(med ~ agent_name, data = d_merged[d_merged$intv_appld=="no", ])
cohen.d(d_merged[d_merged$intv_appld=="yes", ]$med, d_merged[d_merged$intv_appld=="yes", ]$agent_name)
cohen.d(d_merged[d_merged$intv_appld=="no", ]$med, d_merged[d_merged$intv_appld=="no", ]$agent_name)
mediation <- FALSE #change to true if you want to run this code
source("../process.R")
# MODERATED MEDIATION (averaged mediators)
# the effect of intervention on A path (7)
process(data = d_merged, y = "vB_m_v_m_sue", x = "agent_n",
m =c("vB_cntrfctl"), w = "intv_n", model = 7, effsize =1, total =1, stand =1,
contrast =1, boot = 10000 , modelbt = 1, seed = 654321)
## clear workspace
rm(list = ls())
options(download.file.method="libcurl") # sets method for downloading files
setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) # set working directory to current directory
source("../common.R") # install packages; import common plotting functions
## ================================================================================================================
##                                                  PRE-PROCESSING
## ================================================================================================================
## read in data:
d <- read.csv('e1_effect.csv')
## explore dataframe:
dim(d) # will provide dimensions of the dataframe by row [1] and column [2]
colnames(d)
summary(d)
## perform attention exclusions:
# this will remove responses from the dataframe that failed attention checks (i.e., "1" or "2")
d <- subset(d, (d$att1 == 2 & d$att2 == 2))
dim(d) # number of participants should decrease after attention exclusions
## new column to label agent (av/hdv) condition
d$cond <- ifelse(d$FL_4_DO == "FL_39", "av", "hdv") #if FL_40 -> HDV
## get number of participants before comp exclusions
n_orig_all <- dim(d)[1]
n_orig <- as.list(table(d$cond))
## perform comp exclusions
d_clean <- d
d_clean <- subset(d_clean, cruise_familiarity == 2) # remove participants who recognized scenario
d_clean <- subset(d_clean, comp_accident == 1) # include only comp check 2 passes
d_clean <- subset(d_clean, !(cond == "av" & comp1 != 1)) # remove comp check 1 fails for av
d_clean <- subset(d_clean, !(cond == "hdv" & comp1 != 2)) # remove comp check 1 fails for hdv
## get number of participants AFTER exclusions:
n_final_all <- dim(d_clean)[1]
percent_excl_all <- (n_orig_all - n_final_all)/n_orig_all
n_excl_all <- n_orig_all - n_final_all
n_final <- as.list(table(d_clean$cond))
percent_excl <- as.list((table(d$cond) - table(d_clean$cond))/table(d$cond))
## duplicate AV condition vB liability column to match with HDV condition driver liability col
d_clean$vB_mnfctr_sue_AV_2 <- d_clean$vB_mnfctr_sue_AV_1 # duplicate
d_clean <- d_clean %>% relocate(vB_mnfctr_sue_AV_2, .after=vB_mnfctr_sue_AV_1) # move new column
## get mean age and gender:
mean_age = mean(as.numeric(d$age), na.rm = TRUE) # removing NAs from the dataframe before computing mean
gender_f = table(d$gender)["2"]/sum(table(d$gender))
## ================================================================================================================
##                                                    SUBSETTING
## ================================================================================================================
## define new data frame to extract pre-processed data into:
d_merged <- array(dim=c(0, 11))
colnames(d_merged) <- c('vA_sue', 'vB_m_v_d_sue', 'vB_m_v_m_sue', 'vA_cntrfctl', 'vB_cntrfctl',
'avoid', 'comp1', 'comp2', 'mod', 'age', 'cond_name')
d_merged <- as.data.frame(d_merged, stringsAsFactors=FALSE)
## assess moderator data
moderator_mat = d_clean[21:25]
moderator_mat$av_trust_5_1 = 100 - as.numeric(moderator_mat$av_trust_5_1) # reverse code one moderator
moderator_mat <- data.frame(sapply(moderator_mat, as.numeric))
cb_alpha = cronbach.alpha(moderator_mat) # calculate cronbach alpha
d_clean$moderator <- rowMeans(moderator_mat) # averaged moderator measure
d_clean <- d_clean %>% relocate(moderator, .after=comp_accident) # move moderator measure
## select only the used columns
fixed_cols = c(46:48,53,62) # fixed columns - comp checks + mod, age, conditions
d_merged[(dim(d_merged)[1]+1):(dim(d_merged)[1]+n_final$av), ] <- subset(d_clean, cond == "av")[c(30:35,fixed_cols)]
d_merged[(dim(d_merged)[1]+1):(dim(d_merged)[1]+n_final$hdv), ] <- subset(d_clean, cond == "hdv")[c(40:45,fixed_cols)]
# make columns numeric
d_merged[,1:10] <- lapply(d_merged[,1:10], as.numeric)
# average Veh. B counterfactual, and Veh. B could have avoided
d_merged$med <- (d_merged$vB_cntrfctl + d_merged$avoid) / 2
d_merged <- d_merged %>% relocate(med, .after=avoid)
## assign trust levels where low trust=1, high trust=2
d_merged$trust_level <- ifelse(d_merged$mod>50, "high", "low")
d_merged$trust_level_n <- ifelse(d_merged$trust_level=="high",2,1)
# cond_n where av=1, human=2
d_merged$cond_n <- ifelse(d_merged$cond_name=="av", 1, 2)
## ================================================================================================================
##                                             DATA ANALYSIS - T-TESTS
## ================================================================================================================
cor(d_merged[,c(1:7,10)]) # check correlations between measures
## Additional check for discriminant validity
cor.test(d_merged$vB_cntrfctl, d_merged$avoid)
## Sue, at-fault (DV)
t.test(vA_sue ~ cond_name, data = d_merged)
aggregate(vA_sue ~ cond_name, data = d_merged, FUN = sd)
cohen.d(d_merged$vA_sue, d_merged$cond_name)
## Sue, Manufacturer vs Manufacturer (DV)
t.test(vB_m_v_m_sue ~ cond_name, data = d_merged)
aggregate(vB_m_v_m_sue ~ cond_name, data = d_merged, FUN = sd)
cohen.d(d_merged$vB_m_v_m_sue, d_merged$cond_name)
## Sue, Manufacturer vs Driver (DV)
t.test(vB_m_v_d_sue ~ cond_name, data = d_merged)
aggregate(vB_m_v_d_sue ~ cond_name, data = d_merged, FUN = sd)
cohen.d(d_merged$vB_m_v_d_sue, d_merged$cond_name)
## Vehicle A Counterfactual (M)
t.test(vA_cntrfctl ~ cond_name, data = d_merged)
aggregate(vA_cntrfctl ~ cond_name, data = d_merged, FUN = sd)
cohen.d(d_merged$vA_cntrfctl, d_merged$cond_name)
## Vehicle B Counterfactual (M)
t.test(vB_cntrfctl ~ cond_name, data = d_merged)
aggregate(vB_cntrfctl ~ cond_name, data = d_merged, FUN = sd)
cohen.d(d_merged$vB_cntrfctl, d_merged$cond_name)
# Could have done more to avoid (M)
t.test(avoid ~ cond_name, data = d_merged)
aggregate(avoid ~ cond_name, data = d_merged, FUN = sd)
cohen.d(d_merged$avoid, d_merged$cond_name)
# Averaged mediator (M)
t.test(med ~ cond_name, data = d_merged)
aggregate(med ~ cond_name, data = d_merged, FUN = sd)
cohen.d(d_merged$med, d_merged$cond_name)
# Trust (MOD)
t.test(mod ~ cond_name, data = d_merged)
aggregate(mod ~ cond_name, data = d_merged, FUN = sd)
cohen.d(d_merged$mod, d_merged$cond_name)
## trust agreement with counterfactual
t.test(vB_cntrfctl ~ trust_level_n, data = d_merged[d_merged$cond_name=="av", ])
t.test(vB_cntrfctl ~ trust_level_n, data = d_merged[d_merged$cond_name=="hdv", ])
## ================================================================================================================
##                                             MEDIATION ANALYSIS
## ================================================================================================================
mediation <- FALSE #change to true if you want to run this code
source("../process.R")
# PARALLEL MEDIATION
# investigate alternative mediation
process(data = d_merged, y = "vB_m_v_m_sue", x = "cond_n",
m =c("vB_cntrfctl"), model = 4, effsize =1, total =1, stand =1,
contrast =1, boot = 10000 , modelbt = 1, seed = 654321)
## clear workspace
rm(list = ls())
options(download.file.method="libcurl") # sets method for downloading files
setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) # set working directory to current directory
source("../common.R") # install packages; import common plotting functions
## read in data:
d <- read.csv('e1_effect.csv')
## explore dataframe:
dim(d) # will provide dimensions of the dataframe by row [1] and column [2]
colnames(d)
summary(d)
## perform attention exclusions:
# this will remove responses from the dataframe that failed attention checks (i.e., "1" or "2")
d <- subset(d, (d$att1 == 2 & d$att2 == 2))
dim(d) # number of participants should decrease after attention exclusions
## new column to label agent (av/hdv) condition
d$cond <- ifelse(d$FL_4_DO == "FL_39", "av", "hdv") #if FL_40 -> HDV
## get number of participants before comp exclusions
n_orig_all <- dim(d)[1]
n_orig <- as.list(table(d$cond))
## perform comp exclusions
d_clean <- d
d_clean <- subset(d_clean, cruise_familiarity == 2) # remove participants who recognized scenario
d_clean <- subset(d_clean, comp_accident == 1) # include only comp check 2 passes
d_clean <- subset(d_clean, !(cond == "av" & comp1 != 1)) # remove comp check 1 fails for av
d_clean <- subset(d_clean, !(cond == "hdv" & comp1 != 2)) # remove comp check 1 fails for hdv
## get number of participants AFTER exclusions:
n_final_all <- dim(d_clean)[1]
percent_excl_all <- (n_orig_all - n_final_all)/n_orig_all
n_excl_all <- n_orig_all - n_final_all
n_final <- as.list(table(d_clean$cond))
percent_excl <- as.list((table(d$cond) - table(d_clean$cond))/table(d$cond))
## duplicate AV condition vB liability column to match with HDV condition driver liability col
d_clean$vB_mnfctr_sue_AV_2 <- d_clean$vB_mnfctr_sue_AV_1 # duplicate
d_clean <- d_clean %>% relocate(vB_mnfctr_sue_AV_2, .after=vB_mnfctr_sue_AV_1) # move new column
## get mean age and gender:
mean_age = mean(as.numeric(d$age), na.rm = TRUE) # removing NAs from the dataframe before computing mean
gender_f = table(d$gender)["2"]/sum(table(d$gender))
## define new data frame to extract pre-processed data into:
d_merged <- array(dim=c(0, 11))
colnames(d_merged) <- c('vA_sue', 'vB_m_v_d_sue', 'vB_m_v_m_sue', 'vA_cntrfctl', 'vB_cntrfctl',
'avoid', 'comp1', 'comp2', 'mod', 'age', 'cond_name')
d_merged <- as.data.frame(d_merged, stringsAsFactors=FALSE)
## assess moderator data
moderator_mat = d_clean[21:25]
moderator_mat$av_trust_5_1 = 100 - as.numeric(moderator_mat$av_trust_5_1) # reverse code one moderator
moderator_mat <- data.frame(sapply(moderator_mat, as.numeric))
cb_alpha = cronbach.alpha(moderator_mat) # calculate cronbach alpha
d_clean$moderator <- rowMeans(moderator_mat) # averaged moderator measure
d_clean <- d_clean %>% relocate(moderator, .after=comp_accident) # move moderator measure
## select only the used columns
fixed_cols = c(46:48,53,62) # fixed columns - comp checks + mod, age, conditions
d_merged[(dim(d_merged)[1]+1):(dim(d_merged)[1]+n_final$av), ] <- subset(d_clean, cond == "av")[c(30:35,fixed_cols)]
d_merged[(dim(d_merged)[1]+1):(dim(d_merged)[1]+n_final$hdv), ] <- subset(d_clean, cond == "hdv")[c(40:45,fixed_cols)]
# make columns numeric
d_merged[,1:10] <- lapply(d_merged[,1:10], as.numeric)
# average Veh. B counterfactual, and Veh. B could have avoided
d_merged$med <- (d_merged$vB_cntrfctl + d_merged$avoid) / 2
d_merged <- d_merged %>% relocate(med, .after=avoid)
## assign trust levels where low trust=1, high trust=2
d_merged$trust_level <- ifelse(d_merged$mod>50, "high", "low")
d_merged$trust_level_n <- ifelse(d_merged$trust_level=="high",2,1)
# cond_n where av=1, human=2
d_merged$cond_n <- ifelse(d_merged$cond_name=="av", 1, 2)
t_labels <- c("AV", "HDV")
sig_comparisons <- c("av", "hdv")
## Sue, at-fault (DV)
p_val = t.test(vA_sue ~ cond_name, data = d_merged)$p.value
p2_1 <- plot_std(d_merged, x=cond_name, y=vA_sue, p_val,
title="Sue Veh. A Driver", t_labels, sig_comparisons)
## Liable, Manufacturer vs Manufacturer (DV)
p_val = t.test(vB_m_v_m_sue ~ cond_name, data = d_merged)$p.value
p2_2 <- plot_std(d_merged, x=cond_name, y=vB_m_v_m_sue, p_val,
title="Sue Veh. B Manufacturer", t_labels, sig_comparisons)
## Liable, Manufacturer vs Driver (DV)
p_val = t.test(vB_m_v_d_sue ~ cond_name, data = d_merged)$p.value
p2_3 <- plot_std(d_merged, x=cond_name, y=vB_m_v_d_sue, p_val,
title="Sue Veh. B Manufacturer\nor Human Driver", t_labels, sig_comparisons)
## Vehicle A Counterfactual (M)
p_val = t.test(vA_cntrfctl ~ cond_name, data = d_merged)$p.value
p2_4 <- plot_std(d_merged, x=cond_name, y=vA_cntrfctl, p_val,
title="Consider Veh. A Counterfactual", t_labels, sig_comparisons)
## Vehicle B Counterfactual (M)
p_val = t.test(vB_cntrfctl ~ cond_name, data = d_merged)$p.value
p2_5 <- plot_std(d_merged, x=cond_name, y=vB_cntrfctl, p_val,
title="Consider Veh. B Counterfactual", t_labels, sig_comparisons)
## Could have done more to avoid (M)
p_val = t.test(avoid ~ cond_name, data = d_merged)$p.value
p2_6 <- plot_std(d_merged, x=cond_name, y=avoid, p_val,
title="Could Have Done More", t_labels, sig_comparisons)
figure2 <- ggarrange(p2_1, p2_2, p2_3, p2_4, p2_5, p2_6, nrow=2,ncol=3,common.legend = TRUE, legend="top", vjust = 1.0, hjust=0.5)
figure2 <- annotate_figure(figure2,left = text_grob("Mean Agreement", color="black", face ="plain",size=16, rot=90),
bottom = text_grob("Vehicle Type", color="black", face ="plain",size=16))
plot(figure2)
#basic vehicle effect
p_val = t.test(vB_liability ~ agent_name, data = d)$p.value
## clear workspace
rm(list = ls())
options(download.file.method="libcurl") # sets method for downloading files
setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) # set working directory to current directory
source("../common.R") # install packages; import common plotting functions
## ================================================================================================================
##                                                  PRE-PROCESSING
## ================================================================================================================
## read in data:
d_raw <- read.csv('data.csv')
## explore dataframe:
dim(d_raw)
## perform attention exclusions:
# this will remove responses from the dataframe that failed attention checks (i.e., "1" or "2")
d_raw <- subset(d_raw, (d_raw$att1 == 2 & d_raw$att2 == 2))
dim(d_raw)
## new columns to label agent (av/hdv), scenario (cnstr/uncnstr), and condition (combination of the 2)
d_raw$agent_cond <- ifelse(is.na(d_raw$vA_sue_AV_1), "hdv", "av")
d_raw$cond <- paste(d_raw$agent, d_raw$countf, sep="_")
## get number of participants before comp exclusions
n_orig_all <- dim(d_raw)[1]
n_orig <- as.list(table(d_raw$cond))
## perform comp exclusions
d_raw <- subset(d_raw, comp_accident == 1) # include only comp check 2 passes
d_raw <- subset(d_raw, cruise_familiarity == 2)
d_raw <- subset(d_raw, (agent_cond == "av" & comp1 == 1) | (agent_cond == "hdv" & comp1 == 2))
#coder reliability
cor.test(d_raw$coder_1, d_raw$coder_2)
d_raw <- subset(d_raw, (coder_1 == coder_2))
cor.test(d_raw$category_coder1[!is.na(d_raw$category_coder1)],
d_raw$category_coder2[!is.na(d_raw$category_coder2)])
## get number of participants AFTER exclusions:
n_ss <- dim(d_raw)[1]
percent_excl_all <- (n_orig_all - n_ss)/n_orig_all; percent_excl_all
n_excl_all <- n_orig_all - n_ss; n_excl_all
n_excl_all/n_orig_all
table(d_raw$cond)
## get mean age and gender:
mean_age = mean(as.numeric(d_raw$age), na.rm = TRUE); mean_age
gender_f = table(d_raw$gender)["2"]/sum(table(d_raw$gender)); gender_f
## ================================================================================================================
##                                                    SUBSETTING
## ================================================================================================================
## define new data frame to extract pre-processed data into:
d_merged <- array(dim=c(0, 7))
colnames(d_merged) <- c('vA_sue', 'vB_mnfctr_liab', 'vB_mnfctr_liab_2', 'vA_cntrfctl', 'vB_cntrfctl_1', 'vB_cntrfctl_2',
'counterfactual_content')
d_merged <- as.data.frame(d_merged, stringsAsFactors=FALSE)
## select only the used columns
cols_subset <- c(26:31, 36:41)
for(i in 1:n_ss) {
curr <- d_raw[i,cols_subset][!is.na(d_raw[i,cols_subset])] #for a given row, get only the non NA values
d_merged[i,1:6] <- as.numeric(curr[curr!= ""])
d_merged[i,7] <- ifelse(all(d_raw[i,42:43] == ""), d_raw[i,42:43][1], d_raw[i,42:43][d_raw[i,42:43] != ""])
}
# make columns numeric
d_merged[,1:6] <- lapply(d_merged[,1:6], as.numeric)
d <- cbind(d_merged, d_raw[,44:ncol(d_raw)])
# agent_n where av=1, human=2; intv_n where yes=1, no=2
d$agent_n <- ifelse(d$agent_cond=="av", 1, 2)
# reliability
cor(d$vB_mnfctr_liab, d$vB_mnfctr_liab_2)
d$vB_liability <-  (d$vB_mnfctr_liab + d$vB_mnfctr_liab_2)/2 ###
cor(d$vB_cntrfctl_1, d$vB_cntrfctl_2)
d$counterf_med <- (d$vB_cntrfctl_1 + d$vB_cntrfctl_2)/2 ###
#discriminant validity
library(lavaan)
library(semTools)
countf.model <- ' liability   =~ vB_mnfctr_liab + vB_mnfctr_liab_2
counterfactual  =~ vB_cntrfctl_1 + vB_cntrfctl_2 '
htmt(countf.model, d)
## save covariance matrix
countf.cov <- cov(d[, c(2:3, 5:6)])
## HTMT using arithmetic mean
htmt(countf.model, sample.cov = countf.cov, htmt2 = FALSE)
## ================================================================================================================
##                                              PLOTTING 2X2 FIGURE
## ================================================================================================================
#basic vehicle effect
#basic vehicle effect
p_val = t.test(vB_liability ~ agent_cond, data = d)$p.value
fill_labels <- c("AV", "HDV")
d$code <- d$coder_1
#basic vehicle effect
p_val = t.test(vB_liability ~ agent_cond, data = d)$p.value
p0_1 <- plot_std(d, x=agent_cond, y=vB_liability, p_val,
title="Firm Liability", fill_labels, sig_comparisons)
d$agent_cond
fill_labels <- c("AV", "HDV")
sig_comparisons <- c("av", "hdv")
d$code <- d$coder_1
#basic vehicle effect
p_val = t.test(vB_liability ~ agent_cond, data = d)$p.value
p0_1 <- plot_std(d, x=agent_cond, y=vB_liability, p_val,
title="Firm Liability", fill_labels, sig_comparisons)
p0_1
#basic counterfactual effect
p_val = t.test(counterf_med ~ agent_cond, data = d)$p.value
p0_2 <- plot_std(d, x=agent_cond, y=counterf_med, p_val,
title="Firm Liability", fill_labels, sig_comparisons)
p0_2
figure0 <- ggarrange(p0_1, p0_2, nrow=1,ncol=2,common.legend = TRUE, legend="top", vjust = 1.0, hjust=0.5)
figure0
#basic liability effect
p_val = t.test(vB_liability ~ agent_cond, data = d)$p.value
p0_1 <- plot_std(d, x=agent_cond, y=vB_liability, p_val,
title="Firm Liability", fill_labels, sig_comparisons)
#basic counterfactual effect
p_val = t.test(counterf_med ~ agent_cond, data = d)$p.value
p0_2 <- plot_std(d, x=agent_cond, y=counterf_med, p_val,
title="Counterfactual Relevance", fill_labels, sig_comparisons)
figure0 <- ggarrange(p0_1, p0_2, nrow=1,ncol=2,common.legend = TRUE, legend="top", vjust = 1.0, hjust=0.5)
figure0 <- annotate_figure(figure2,left = text_grob("Mean Agreement", color="black", face ="plain",size=16, rot=90),
bottom = text_grob("Vehicle Type", color="black", face ="plain",size=16))
figure0
p_val_L = t.test(counterf_med ~ agent_cond, data = d[d$code == 1, ])$p.value
p_val_R = t.test(counterf_med ~ agent_cond, data = d[d$code == 2, ])$p.value
p1_2 <- plot_2x2(d, x=code, y=counterf_med, fill=agent_cond, p_val_L, p_val_R,
title="Counterfactual Relevance", c("No", "Yes"), fill_labels)
p1_2
## Understanding why counterfactual means are flat
p_val_L = t.test(counterf_med ~ code, data = d[d$agent_cond == "av", ])$p.value
p_val_R = t.test(counterf_med ~ code, data = d[d$agent_cond == "hdv", ])$p.value
code_labels <- c("1", "2")
p1_2 <- plot_2x2(d, x=agent_cond, y=counterf_med, fill=code, p_val_L, p_val_R,
title="Counterfactual Relevance", c("No", "Yes"), code_labels)
p1_2
code_labels <- c("1", "2")
p1_2 <- plot_2x2(d, x=agent_cond, y=counterf_med, fill=code, p_val_L, p_val_R,
title="Counterfactual Relevance", c("No", "Yes"), code_labels)
p1_2
p1_2 <- plot_2x2(d, x=agent_cond, y=counterf_med, fill=code, p_val_L, p_val_R,
title="Counterfactual Relevance", c("AV", "HDV"), code_labels)
p1_2
## Understanding why counterfactual means are flat
p_val_L = t.test(counterf_med ~ code, data = d[d$agent_cond == "av", ])$p.value
p_val_R = t.test(counterf_med ~ code, data = d[d$agent_cond == "hdv", ])$p.value
code_labels <- c("1", "2")
p1_2 <- plot_2x2(d, x=agent_cond, y=counterf_med, fill=code, p_val_L, p_val_R,
title="Counterfactual Relevance", c("AV", "HDV"), code_labels)
p1_2
d$agent_cond
d$counterf_med
p1_2 <- plot_2x2(d, x=agent_cond, y=counterf_med, fill=code, p_val_L, p_val_R,
title="Counterfactual Relevance", c("AV", "HDV"), code_labels)
p1_2
p1_2 <- plot_2x2(d, x=agent_cond, y=counterf_med, fill=as.factor(code), p_val_L, p_val_R,
title="Counterfactual Relevance", c("AV", "HDV"), code_labels)
p1_2
#basic liability effect
p_val = t.test(vB_liability ~ agent_cond, data = d)$p.value
p0_1 <- plot_std(d, x=agent_cond, y=vB_liability, p_val,
title="Firm Liability", fill_labels, sig_comparisons)
#basic counterfactual effect
p_val = t.test(counterf_med ~ agent_cond, data = d)$p.value
p0_2 <- plot_std(d, x=agent_cond, y=counterf_med, p_val,
title="Counterfactual Relevance", fill_labels, sig_comparisons)
## Understanding why counterfactual means are flat
p_val_L = t.test(counterf_med ~ code, data = d[d$agent_cond == "av", ])$p.value
p_val_R = t.test(counterf_med ~ code, data = d[d$agent_cond == "hdv", ])$p.value
code_labels <- c("1", "2")
p0_3 <- plot_2x2(d, x=agent_cond, y=counterf_med, fill=as.factor(code), p_val_L, p_val_R,
title="Counterfactual Relevance", c("AV", "HDV"), code_labels)
p0_3
figure0 <- ggarrange(p0_1, p0_2, p0_3, nrow=1,ncol=3,common.legend = TRUE, legend="top", vjust = 1.0, hjust=0.5)
figure0 <- annotate_figure(figure2,left = text_grob("Mean Agreement", color="black", face ="plain",size=16, rot=90),
bottom = text_grob("Vehicle Type", color="black", face ="plain",size=16))
figure0
#t-tests
t.test(counterf_med ~ code, data = d, subset = agent_cond == "av")
cohen.d(d$counterf_med[d$agent_cond=="av"], d$agent_cond[d$agent_cond=="av"])
#t-tests
t.test(counterf_med ~ code, data = d, subset = agent_cond == "av")
cohen.d(d$counterf_med[d$agent_cond=="av"], d$code[d$agent_cond=="av"])
t.test(counterf_med ~ code, data = d, subset = agent_cond == "hdvÃŸ")
t.test(counterf_med ~ code, data = d, subset = agent_cond == "hdv")
cohen.d(d$counterf_med[d$agent_cond=="hdv"], d$code[d$agent_cond=="hdv"])
#t-tests
t.test(counterf_med ~ code, data = d, subset = agent_cond == "av")
cohen.d(d$counterf_med[d$agent_cond=="av"], d$code[d$agent_cond=="av"])
t.test(counterf_med ~ code, data = d, subset = agent_cond == "hdv")
cohen.d(d$counterf_med[d$agent_cond=="hdv"], d$code[d$agent_cond=="hdv"])
aggregate(counterf_med ~ agent_cond, data = d, FUN = mean)
#t-tests
t.test(counterf_med ~ code, data = d, subset = agent_cond == "hdv")
cohen.d(d$counterf_med[d$agent_cond=="hdv"], d$code[d$agent_cond=="hdv"])
t.test(counterf_med ~ code, data = d, subset = agent_cond == "av")
cohen.d(d$counterf_med[d$agent_cond=="av"], d$code[d$agent_cond=="av"])
cohen.d(d$counterf_med[d$agent_cond=="hdv"], d$code[d$agent_cond=="hdv"])
cohen.d(d$counterf_med[d$agent_cond=="av"], d$code[d$agent_cond=="av"])
d$counterf_med[d$agent_cond=="hdv"]
d$code[d$agent_cond=="hdv"]
d$counterf_med[d$agent_cond=="av"]
cohen.d(d$counterf_med[d$agent_cond=="hdv"], d$code[d$agent_cond=="hdv"])
#t-tests
t.test(counterf_med ~ code, data = d, subset = agent_cond == "hdv")
aggregate(counterf_med ~ agent_cond, data = d, FUN = mean)
## clear workspace
rm(list = ls())
options(download.file.method="libcurl") # sets method for downloading files
setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) # set working directory to current directory
source("../common.R") # install packages; import common plotting functions
## ================================================================================================================
##                                                  PRE-PROCESSING
## ================================================================================================================
## read in data:
d_raw <- read.csv('data.csv')
## explore dataframe:
dim(d_raw)
## perform attention exclusions:
# this will remove responses from the dataframe that failed attention checks (i.e., "1" or "2")
d_raw <- subset(d_raw, (d_raw$att1 == 2 & d_raw$att2 == 2))
dim(d_raw)
## new columns to label agent (av/hdv), scenario (cnstr/uncnstr), and condition (combination of the 2)
d_raw$agent_cond <- ifelse(is.na(d_raw$vA_sue_AV_1), "hdv", "av")
d_raw$cond <- paste(d_raw$agent, d_raw$countf, sep="_")
## get number of participants before comp exclusions
n_orig_all <- dim(d_raw)[1]
n_orig <- as.list(table(d_raw$cond))
## perform comp exclusions
d_raw <- subset(d_raw, comp_accident == 1) # include only comp check 2 passes
d_raw <- subset(d_raw, cruise_familiarity == 2)
d_raw <- subset(d_raw, (agent_cond == "av" & comp1 == 1) | (agent_cond == "hdv" & comp1 == 2))
#coder reliability
cor.test(d_raw$coder_1, d_raw$coder_2)
d_raw <- subset(d_raw, (coder_1 == coder_2))
cor.test(d_raw$category_coder1[!is.na(d_raw$category_coder1)],
d_raw$category_coder2[!is.na(d_raw$category_coder2)])
## get number of participants AFTER exclusions:
n_ss <- dim(d_raw)[1]
percent_excl_all <- (n_orig_all - n_ss)/n_orig_all; percent_excl_all
## clear workspace
rm(list = ls())
options(download.file.method="libcurl") # sets method for downloading files
setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) # set working directory to current directory
source("../common.R") # install packages; import common plotting functions
## ================================================================================================================
##                                                  PRE-PROCESSING
## ================================================================================================================
## read in data:
d_raw <- read.csv('e2_counterf_gen.csv')
## explore dataframe:
dim(d_raw)
